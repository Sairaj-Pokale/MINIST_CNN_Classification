{"cells":[{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","from torch.utils.data import DataLoader\n","import torch"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 30539723.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 28889981.83it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 1648877/1648877 [00:00<00:00, 10896538.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 4519698.40it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["traindata = datasets.MNIST(\n","    root= 'data',\n","    train=True,\n","    transform=ToTensor(),\n","    download= True\n",")\n","\n","testdata = datasets.MNIST(\n","    root= 'data',\n","    train=False,\n","    transform=ToTensor(),\n","    download= True\n",")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["Dataset MNIST\n","    Number of datapoints: 60000\n","    Root location: data\n","    Split: Train\n","    StandardTransform\n","Transform: ToTensor()"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["traindata"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["Dataset MNIST\n","    Number of datapoints: 10000\n","    Root location: data\n","    Split: Test\n","    StandardTransform\n","Transform: ToTensor()"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["testdata"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([28, 28])\n","torch.Size([60000, 28, 28])\n"]}],"source":["print(traindata.data[1].shape)\n","print(traindata.data.shape)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([10000, 28, 28])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["testdata.data.shape"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["train_loader = DataLoader(traindata, batch_size=100, shuffle=True, num_workers=1)\n","test_loader = DataLoader(testdata, batch_size=100, shuffle=True, num_workers=1)\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([7, 6, 1, 4, 0, 7, 3, 2, 1, 0, 5, 8, 0, 1, 1, 3, 1, 6, 1, 6, 6, 4, 4, 2,\n","        0, 7, 7, 1, 0, 3, 0, 5, 3, 3, 1, 9, 1, 7, 8, 1, 3, 0, 5, 0, 4, 4, 5, 2,\n","        5, 1, 1, 6, 6, 7, 9, 7, 4, 4, 3, 3, 6, 1, 5, 1, 3, 8, 8, 4, 0, 3, 5, 7,\n","        0, 0, 3, 3, 4, 8, 0, 5, 9, 3, 7, 6, 5, 0, 2, 4, 0, 6, 6, 3, 9, 0, 8, 3,\n","        4, 5, 7, 4])\n"]}],"source":["dataiter = iter(train_loader)\n","data = next(dataiter)\n","feat, tar = data\n","print(feat, tar)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<torch.utils.data.dataloader.DataLoader object at 0x00000287F5EAA250>\n","<torch.utils.data.dataloader.DataLoader object at 0x00000287F6612F90>\n"]}],"source":["print(train_loader)\n","print(test_loader)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as f\n","import torch.optim as optim\n","\n","\n","class CNN(nn.Module):\n","    def __init__(self) :\n","        super(CNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(320, 50)\n","        self.fc2 = nn.Linear(50,10)\n","\n","    def forward(self, X):\n","        X = f.relu(f.max_pool2d(self.conv1(X), 2))\n","        X = f.relu(f.max_pool2d(self.conv2_drop(self.conv2(X)), 2))\n","        X = X.view(-1, 320)\n","        X = f.relu(self.fc1(X))\n","        X = f.dropout(X, training=self.training)\n","        X = self.fc2(X)\n","\n","        return f.softmax(X)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = CNN().to(device)\n","\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def train(epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = loss_fn(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 20 == 0:\n","            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{(len(train_loader)*100)} ({100. * batch_idx / len(train_loader):.0f}%)]\\t{loss.item(): .6f}')\n","\n","\n","def test():\n","    model.eval()\n","\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += loss_fn(output, target).item()\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","        \n","    test_loss /= len(test_loader)\n","    print(f'\\nTest set: Average Loss: {test_loss:.4f}, Accuracy {correct}/{(len(test_loader)*100)} ({(100. * correct / (len(test_loader)*100)):.0f}%\\n)')\n"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\saira\\AppData\\Local\\Temp\\ipykernel_8728\\954177959.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return f.softmax(X)\n"]},{"name":"stdout","output_type":"stream","text":["Train Epoch: 1 [0/60000 (0%)]\t 2.303523\n","Train Epoch: 1 [2000/60000 (3%)]\t 2.282403\n","Train Epoch: 1 [4000/60000 (7%)]\t 2.150484\n","Train Epoch: 1 [6000/60000 (10%)]\t 1.921887\n","Train Epoch: 1 [8000/60000 (13%)]\t 1.804797\n","Train Epoch: 1 [10000/60000 (17%)]\t 1.805525\n","Train Epoch: 1 [12000/60000 (20%)]\t 1.740674\n","Train Epoch: 1 [14000/60000 (23%)]\t 1.727288\n","Train Epoch: 1 [16000/60000 (27%)]\t 1.732427\n","Train Epoch: 1 [18000/60000 (30%)]\t 1.639903\n","Train Epoch: 1 [20000/60000 (33%)]\t 1.663262\n","Train Epoch: 1 [22000/60000 (37%)]\t 1.694451\n","Train Epoch: 1 [24000/60000 (40%)]\t 1.648265\n","Train Epoch: 1 [26000/60000 (43%)]\t 1.659808\n","Train Epoch: 1 [28000/60000 (47%)]\t 1.634784\n","Train Epoch: 1 [30000/60000 (50%)]\t 1.702483\n","Train Epoch: 1 [32000/60000 (53%)]\t 1.595972\n","Train Epoch: 1 [34000/60000 (57%)]\t 1.555587\n","Train Epoch: 1 [36000/60000 (60%)]\t 1.677710\n","Train Epoch: 1 [38000/60000 (63%)]\t 1.599350\n","Train Epoch: 1 [40000/60000 (67%)]\t 1.597785\n","Train Epoch: 1 [42000/60000 (70%)]\t 1.642197\n","Train Epoch: 1 [44000/60000 (73%)]\t 1.574365\n","Train Epoch: 1 [46000/60000 (77%)]\t 1.607885\n","Train Epoch: 1 [48000/60000 (80%)]\t 1.605643\n","Train Epoch: 1 [50000/60000 (83%)]\t 1.592783\n","Train Epoch: 1 [52000/60000 (87%)]\t 1.594678\n","Train Epoch: 1 [54000/60000 (90%)]\t 1.617080\n","Train Epoch: 1 [56000/60000 (93%)]\t 1.625331\n","Train Epoch: 1 [58000/60000 (97%)]\t 1.569232\n","\n","Test set: Average Loss: 1.5217, Accuracy 9410/10000 (94%\n",")\n","Train Epoch: 2 [0/60000 (0%)]\t 1.527850\n","Train Epoch: 2 [2000/60000 (3%)]\t 1.628443\n","Train Epoch: 2 [4000/60000 (7%)]\t 1.610849\n","Train Epoch: 2 [6000/60000 (10%)]\t 1.573945\n","Train Epoch: 2 [8000/60000 (13%)]\t 1.568285\n","Train Epoch: 2 [10000/60000 (17%)]\t 1.601906\n","Train Epoch: 2 [12000/60000 (20%)]\t 1.574756\n","Train Epoch: 2 [14000/60000 (23%)]\t 1.587689\n","Train Epoch: 2 [16000/60000 (27%)]\t 1.551157\n","Train Epoch: 2 [18000/60000 (30%)]\t 1.586364\n","Train Epoch: 2 [20000/60000 (33%)]\t 1.531617\n","Train Epoch: 2 [22000/60000 (37%)]\t 1.580746\n","Train Epoch: 2 [24000/60000 (40%)]\t 1.651730\n","Train Epoch: 2 [26000/60000 (43%)]\t 1.614879\n","Train Epoch: 2 [28000/60000 (47%)]\t 1.559881\n","Train Epoch: 2 [30000/60000 (50%)]\t 1.527172\n","Train Epoch: 2 [32000/60000 (53%)]\t 1.575097\n","Train Epoch: 2 [34000/60000 (57%)]\t 1.585157\n","Train Epoch: 2 [36000/60000 (60%)]\t 1.633943\n","Train Epoch: 2 [38000/60000 (63%)]\t 1.624374\n","Train Epoch: 2 [40000/60000 (67%)]\t 1.523916\n","Train Epoch: 2 [42000/60000 (70%)]\t 1.578149\n","Train Epoch: 2 [44000/60000 (73%)]\t 1.575934\n","Train Epoch: 2 [46000/60000 (77%)]\t 1.565561\n","Train Epoch: 2 [48000/60000 (80%)]\t 1.560395\n","Train Epoch: 2 [50000/60000 (83%)]\t 1.539999\n","Train Epoch: 2 [52000/60000 (87%)]\t 1.544999\n","Train Epoch: 2 [54000/60000 (90%)]\t 1.580509\n","Train Epoch: 2 [56000/60000 (93%)]\t 1.563182\n","Train Epoch: 2 [58000/60000 (97%)]\t 1.558445\n","\n","Test set: Average Loss: 1.5072, Accuracy 9545/10000 (95%\n",")\n","Train Epoch: 3 [0/60000 (0%)]\t 1.573712\n","Train Epoch: 3 [2000/60000 (3%)]\t 1.577661\n","Train Epoch: 3 [4000/60000 (7%)]\t 1.579372\n","Train Epoch: 3 [6000/60000 (10%)]\t 1.622102\n","Train Epoch: 3 [8000/60000 (13%)]\t 1.535359\n","Train Epoch: 3 [10000/60000 (17%)]\t 1.504852\n","Train Epoch: 3 [12000/60000 (20%)]\t 1.590688\n","Train Epoch: 3 [14000/60000 (23%)]\t 1.570637\n","Train Epoch: 3 [16000/60000 (27%)]\t 1.565296\n","Train Epoch: 3 [18000/60000 (30%)]\t 1.545399\n","Train Epoch: 3 [20000/60000 (33%)]\t 1.629210\n","Train Epoch: 3 [22000/60000 (37%)]\t 1.578171\n","Train Epoch: 3 [24000/60000 (40%)]\t 1.538250\n","Train Epoch: 3 [26000/60000 (43%)]\t 1.556839\n","Train Epoch: 3 [28000/60000 (47%)]\t 1.567830\n","Train Epoch: 3 [30000/60000 (50%)]\t 1.558761\n","Train Epoch: 3 [32000/60000 (53%)]\t 1.563011\n","Train Epoch: 3 [34000/60000 (57%)]\t 1.555928\n","Train Epoch: 3 [36000/60000 (60%)]\t 1.555895\n","Train Epoch: 3 [38000/60000 (63%)]\t 1.595748\n","Train Epoch: 3 [40000/60000 (67%)]\t 1.490941\n","Train Epoch: 3 [42000/60000 (70%)]\t 1.567011\n","Train Epoch: 3 [44000/60000 (73%)]\t 1.586219\n","Train Epoch: 3 [46000/60000 (77%)]\t 1.513729\n","Train Epoch: 3 [48000/60000 (80%)]\t 1.558438\n","Train Epoch: 3 [50000/60000 (83%)]\t 1.504515\n","Train Epoch: 3 [52000/60000 (87%)]\t 1.542029\n","Train Epoch: 3 [54000/60000 (90%)]\t 1.530458\n","Train Epoch: 3 [56000/60000 (93%)]\t 1.547814\n","Train Epoch: 3 [58000/60000 (97%)]\t 1.513599\n","\n","Test set: Average Loss: 1.5001, Accuracy 9611/10000 (96%\n",")\n","Train Epoch: 4 [0/60000 (0%)]\t 1.543239\n","Train Epoch: 4 [2000/60000 (3%)]\t 1.531378\n","Train Epoch: 4 [4000/60000 (7%)]\t 1.520935\n","Train Epoch: 4 [6000/60000 (10%)]\t 1.537836\n","Train Epoch: 4 [8000/60000 (13%)]\t 1.524941\n","Train Epoch: 4 [10000/60000 (17%)]\t 1.541367\n","Train Epoch: 4 [12000/60000 (20%)]\t 1.512752\n","Train Epoch: 4 [14000/60000 (23%)]\t 1.519185\n","Train Epoch: 4 [16000/60000 (27%)]\t 1.549786\n","Train Epoch: 4 [18000/60000 (30%)]\t 1.572701\n","Train Epoch: 4 [20000/60000 (33%)]\t 1.589464\n","Train Epoch: 4 [22000/60000 (37%)]\t 1.517387\n","Train Epoch: 4 [24000/60000 (40%)]\t 1.578189\n","Train Epoch: 4 [26000/60000 (43%)]\t 1.508161\n","Train Epoch: 4 [28000/60000 (47%)]\t 1.542105\n","Train Epoch: 4 [30000/60000 (50%)]\t 1.534043\n","Train Epoch: 4 [32000/60000 (53%)]\t 1.492847\n","Train Epoch: 4 [34000/60000 (57%)]\t 1.561071\n","Train Epoch: 4 [36000/60000 (60%)]\t 1.532073\n","Train Epoch: 4 [38000/60000 (63%)]\t 1.546761\n","Train Epoch: 4 [40000/60000 (67%)]\t 1.524379\n","Train Epoch: 4 [42000/60000 (70%)]\t 1.522191\n","Train Epoch: 4 [44000/60000 (73%)]\t 1.564807\n","Train Epoch: 4 [46000/60000 (77%)]\t 1.533829\n","Train Epoch: 4 [48000/60000 (80%)]\t 1.543542\n","Train Epoch: 4 [50000/60000 (83%)]\t 1.611750\n","Train Epoch: 4 [52000/60000 (87%)]\t 1.547817\n","Train Epoch: 4 [54000/60000 (90%)]\t 1.568547\n","Train Epoch: 4 [56000/60000 (93%)]\t 1.519705\n","Train Epoch: 4 [58000/60000 (97%)]\t 1.569584\n","\n","Test set: Average Loss: 1.4967, Accuracy 9644/10000 (96%\n",")\n","Train Epoch: 5 [0/60000 (0%)]\t 1.538131\n","Train Epoch: 5 [2000/60000 (3%)]\t 1.540791\n","Train Epoch: 5 [4000/60000 (7%)]\t 1.553011\n","Train Epoch: 5 [6000/60000 (10%)]\t 1.575301\n","Train Epoch: 5 [8000/60000 (13%)]\t 1.569836\n","Train Epoch: 5 [10000/60000 (17%)]\t 1.507573\n","Train Epoch: 5 [12000/60000 (20%)]\t 1.562963\n","Train Epoch: 5 [14000/60000 (23%)]\t 1.511312\n","Train Epoch: 5 [16000/60000 (27%)]\t 1.511684\n","Train Epoch: 5 [18000/60000 (30%)]\t 1.502023\n","Train Epoch: 5 [20000/60000 (33%)]\t 1.528879\n","Train Epoch: 5 [22000/60000 (37%)]\t 1.545297\n","Train Epoch: 5 [24000/60000 (40%)]\t 1.475821\n","Train Epoch: 5 [26000/60000 (43%)]\t 1.523307\n","Train Epoch: 5 [28000/60000 (47%)]\t 1.543346\n","Train Epoch: 5 [30000/60000 (50%)]\t 1.520966\n","Train Epoch: 5 [32000/60000 (53%)]\t 1.526235\n","Train Epoch: 5 [34000/60000 (57%)]\t 1.565011\n","Train Epoch: 5 [36000/60000 (60%)]\t 1.519962\n","Train Epoch: 5 [38000/60000 (63%)]\t 1.527389\n","Train Epoch: 5 [40000/60000 (67%)]\t 1.559988\n","Train Epoch: 5 [42000/60000 (70%)]\t 1.520407\n","Train Epoch: 5 [44000/60000 (73%)]\t 1.550525\n","Train Epoch: 5 [46000/60000 (77%)]\t 1.534377\n","Train Epoch: 5 [48000/60000 (80%)]\t 1.584269\n","Train Epoch: 5 [50000/60000 (83%)]\t 1.511711\n","Train Epoch: 5 [52000/60000 (87%)]\t 1.565089\n","Train Epoch: 5 [54000/60000 (90%)]\t 1.525567\n","Train Epoch: 5 [56000/60000 (93%)]\t 1.523413\n","Train Epoch: 5 [58000/60000 (97%)]\t 1.507362\n","\n","Test set: Average Loss: 1.4932, Accuracy 9681/10000 (97%\n",")\n","Train Epoch: 6 [0/60000 (0%)]\t 1.576204\n","Train Epoch: 6 [2000/60000 (3%)]\t 1.534765\n","Train Epoch: 6 [4000/60000 (7%)]\t 1.555282\n","Train Epoch: 6 [6000/60000 (10%)]\t 1.522217\n","Train Epoch: 6 [8000/60000 (13%)]\t 1.519189\n","Train Epoch: 6 [10000/60000 (17%)]\t 1.501919\n","Train Epoch: 6 [12000/60000 (20%)]\t 1.547233\n","Train Epoch: 6 [14000/60000 (23%)]\t 1.516160\n","Train Epoch: 6 [16000/60000 (27%)]\t 1.521560\n","Train Epoch: 6 [18000/60000 (30%)]\t 1.538053\n","Train Epoch: 6 [20000/60000 (33%)]\t 1.503622\n","Train Epoch: 6 [22000/60000 (37%)]\t 1.540263\n","Train Epoch: 6 [24000/60000 (40%)]\t 1.569115\n","Train Epoch: 6 [26000/60000 (43%)]\t 1.540326\n","Train Epoch: 6 [28000/60000 (47%)]\t 1.537052\n","Train Epoch: 6 [30000/60000 (50%)]\t 1.526371\n","Train Epoch: 6 [32000/60000 (53%)]\t 1.540105\n","Train Epoch: 6 [34000/60000 (57%)]\t 1.527723\n","Train Epoch: 6 [36000/60000 (60%)]\t 1.553522\n","Train Epoch: 6 [38000/60000 (63%)]\t 1.548421\n","Train Epoch: 6 [40000/60000 (67%)]\t 1.533308\n","Train Epoch: 6 [42000/60000 (70%)]\t 1.531869\n","Train Epoch: 6 [44000/60000 (73%)]\t 1.543122\n","Train Epoch: 6 [46000/60000 (77%)]\t 1.507043\n","Train Epoch: 6 [48000/60000 (80%)]\t 1.500473\n","Train Epoch: 6 [50000/60000 (83%)]\t 1.536348\n","Train Epoch: 6 [52000/60000 (87%)]\t 1.537657\n","Train Epoch: 6 [54000/60000 (90%)]\t 1.526217\n","Train Epoch: 6 [56000/60000 (93%)]\t 1.497102\n","Train Epoch: 6 [58000/60000 (97%)]\t 1.593512\n","\n","Test set: Average Loss: 1.4912, Accuracy 9704/10000 (97%\n",")\n","Train Epoch: 7 [0/60000 (0%)]\t 1.531845\n","Train Epoch: 7 [2000/60000 (3%)]\t 1.553610\n","Train Epoch: 7 [4000/60000 (7%)]\t 1.548157\n","Train Epoch: 7 [6000/60000 (10%)]\t 1.524332\n","Train Epoch: 7 [8000/60000 (13%)]\t 1.533880\n","Train Epoch: 7 [10000/60000 (17%)]\t 1.523909\n","Train Epoch: 7 [12000/60000 (20%)]\t 1.492846\n","Train Epoch: 7 [14000/60000 (23%)]\t 1.569617\n","Train Epoch: 7 [16000/60000 (27%)]\t 1.512325\n","Train Epoch: 7 [18000/60000 (30%)]\t 1.529998\n","Train Epoch: 7 [20000/60000 (33%)]\t 1.547816\n","Train Epoch: 7 [22000/60000 (37%)]\t 1.519495\n","Train Epoch: 7 [24000/60000 (40%)]\t 1.479656\n","Train Epoch: 7 [26000/60000 (43%)]\t 1.524452\n","Train Epoch: 7 [28000/60000 (47%)]\t 1.509978\n","Train Epoch: 7 [30000/60000 (50%)]\t 1.490478\n","Train Epoch: 7 [32000/60000 (53%)]\t 1.526748\n","Train Epoch: 7 [34000/60000 (57%)]\t 1.509325\n","Train Epoch: 7 [36000/60000 (60%)]\t 1.537002\n","Train Epoch: 7 [38000/60000 (63%)]\t 1.561841\n","Train Epoch: 7 [40000/60000 (67%)]\t 1.550192\n","Train Epoch: 7 [42000/60000 (70%)]\t 1.512276\n","Train Epoch: 7 [44000/60000 (73%)]\t 1.525160\n","Train Epoch: 7 [46000/60000 (77%)]\t 1.525429\n","Train Epoch: 7 [48000/60000 (80%)]\t 1.549334\n","Train Epoch: 7 [50000/60000 (83%)]\t 1.537647\n","Train Epoch: 7 [52000/60000 (87%)]\t 1.514288\n","Train Epoch: 7 [54000/60000 (90%)]\t 1.531713\n","Train Epoch: 7 [56000/60000 (93%)]\t 1.516201\n","Train Epoch: 7 [58000/60000 (97%)]\t 1.522545\n","\n","Test set: Average Loss: 1.4883, Accuracy 9732/10000 (97%\n",")\n","Train Epoch: 8 [0/60000 (0%)]\t 1.559158\n","Train Epoch: 8 [2000/60000 (3%)]\t 1.559361\n","Train Epoch: 8 [4000/60000 (7%)]\t 1.550822\n","Train Epoch: 8 [6000/60000 (10%)]\t 1.557566\n","Train Epoch: 8 [8000/60000 (13%)]\t 1.539289\n","Train Epoch: 8 [10000/60000 (17%)]\t 1.524170\n","Train Epoch: 8 [12000/60000 (20%)]\t 1.510827\n","Train Epoch: 8 [14000/60000 (23%)]\t 1.524029\n","Train Epoch: 8 [16000/60000 (27%)]\t 1.516205\n","Train Epoch: 8 [18000/60000 (30%)]\t 1.513261\n","Train Epoch: 8 [20000/60000 (33%)]\t 1.524312\n","Train Epoch: 8 [22000/60000 (37%)]\t 1.548868\n","Train Epoch: 8 [24000/60000 (40%)]\t 1.502493\n","Train Epoch: 8 [26000/60000 (43%)]\t 1.499249\n","Train Epoch: 8 [28000/60000 (47%)]\t 1.542858\n","Train Epoch: 8 [30000/60000 (50%)]\t 1.520061\n","Train Epoch: 8 [32000/60000 (53%)]\t 1.563445\n","Train Epoch: 8 [34000/60000 (57%)]\t 1.511656\n","Train Epoch: 8 [36000/60000 (60%)]\t 1.540334\n","Train Epoch: 8 [38000/60000 (63%)]\t 1.539919\n","Train Epoch: 8 [40000/60000 (67%)]\t 1.482584\n","Train Epoch: 8 [42000/60000 (70%)]\t 1.525117\n","Train Epoch: 8 [44000/60000 (73%)]\t 1.526081\n","Train Epoch: 8 [46000/60000 (77%)]\t 1.519246\n","Train Epoch: 8 [48000/60000 (80%)]\t 1.501564\n","Train Epoch: 8 [50000/60000 (83%)]\t 1.511948\n","Train Epoch: 8 [52000/60000 (87%)]\t 1.501415\n","Train Epoch: 8 [54000/60000 (90%)]\t 1.558436\n","Train Epoch: 8 [56000/60000 (93%)]\t 1.511717\n","Train Epoch: 8 [58000/60000 (97%)]\t 1.521901\n","\n","Test set: Average Loss: 1.4873, Accuracy 9737/10000 (97%\n",")\n","Train Epoch: 9 [0/60000 (0%)]\t 1.533281\n","Train Epoch: 9 [2000/60000 (3%)]\t 1.550102\n","Train Epoch: 9 [4000/60000 (7%)]\t 1.513092\n","Train Epoch: 9 [6000/60000 (10%)]\t 1.538938\n","Train Epoch: 9 [8000/60000 (13%)]\t 1.565152\n","Train Epoch: 9 [10000/60000 (17%)]\t 1.502210\n","Train Epoch: 9 [12000/60000 (20%)]\t 1.534814\n","Train Epoch: 9 [14000/60000 (23%)]\t 1.490052\n","Train Epoch: 9 [16000/60000 (27%)]\t 1.521479\n","Train Epoch: 9 [18000/60000 (30%)]\t 1.525044\n","Train Epoch: 9 [20000/60000 (33%)]\t 1.542612\n","Train Epoch: 9 [22000/60000 (37%)]\t 1.523818\n","Train Epoch: 9 [24000/60000 (40%)]\t 1.515454\n","Train Epoch: 9 [26000/60000 (43%)]\t 1.520233\n","Train Epoch: 9 [28000/60000 (47%)]\t 1.520327\n","Train Epoch: 9 [30000/60000 (50%)]\t 1.501176\n","Train Epoch: 9 [32000/60000 (53%)]\t 1.527919\n","Train Epoch: 9 [34000/60000 (57%)]\t 1.514391\n","Train Epoch: 9 [36000/60000 (60%)]\t 1.538561\n","Train Epoch: 9 [38000/60000 (63%)]\t 1.545478\n","Train Epoch: 9 [40000/60000 (67%)]\t 1.530746\n","Train Epoch: 9 [42000/60000 (70%)]\t 1.503054\n","Train Epoch: 9 [44000/60000 (73%)]\t 1.521758\n","Train Epoch: 9 [46000/60000 (77%)]\t 1.558173\n","Train Epoch: 9 [48000/60000 (80%)]\t 1.527668\n","Train Epoch: 9 [50000/60000 (83%)]\t 1.488295\n","Train Epoch: 9 [52000/60000 (87%)]\t 1.538109\n","Train Epoch: 9 [54000/60000 (90%)]\t 1.527108\n","Train Epoch: 9 [56000/60000 (93%)]\t 1.507301\n","Train Epoch: 9 [58000/60000 (97%)]\t 1.514843\n","\n","Test set: Average Loss: 1.4866, Accuracy 9745/10000 (97%\n",")\n","Train Epoch: 10 [0/60000 (0%)]\t 1.485040\n","Train Epoch: 10 [2000/60000 (3%)]\t 1.498483\n","Train Epoch: 10 [4000/60000 (7%)]\t 1.495883\n","Train Epoch: 10 [6000/60000 (10%)]\t 1.493477\n","Train Epoch: 10 [8000/60000 (13%)]\t 1.530093\n","Train Epoch: 10 [10000/60000 (17%)]\t 1.523129\n","Train Epoch: 10 [12000/60000 (20%)]\t 1.502538\n","Train Epoch: 10 [14000/60000 (23%)]\t 1.505462\n","Train Epoch: 10 [16000/60000 (27%)]\t 1.495582\n","Train Epoch: 10 [18000/60000 (30%)]\t 1.544979\n","Train Epoch: 10 [20000/60000 (33%)]\t 1.545644\n","Train Epoch: 10 [22000/60000 (37%)]\t 1.552115\n","Train Epoch: 10 [24000/60000 (40%)]\t 1.520896\n","Train Epoch: 10 [26000/60000 (43%)]\t 1.525355\n","Train Epoch: 10 [28000/60000 (47%)]\t 1.515727\n","Train Epoch: 10 [30000/60000 (50%)]\t 1.538115\n","Train Epoch: 10 [32000/60000 (53%)]\t 1.546679\n","Train Epoch: 10 [34000/60000 (57%)]\t 1.568247\n","Train Epoch: 10 [36000/60000 (60%)]\t 1.529546\n","Train Epoch: 10 [38000/60000 (63%)]\t 1.484425\n","Train Epoch: 10 [40000/60000 (67%)]\t 1.516746\n","Train Epoch: 10 [42000/60000 (70%)]\t 1.502852\n","Train Epoch: 10 [44000/60000 (73%)]\t 1.545392\n","Train Epoch: 10 [46000/60000 (77%)]\t 1.496240\n","Train Epoch: 10 [48000/60000 (80%)]\t 1.517372\n","Train Epoch: 10 [50000/60000 (83%)]\t 1.501369\n","Train Epoch: 10 [52000/60000 (87%)]\t 1.510692\n","Train Epoch: 10 [54000/60000 (90%)]\t 1.506261\n","Train Epoch: 10 [56000/60000 (93%)]\t 1.507494\n","Train Epoch: 10 [58000/60000 (97%)]\t 1.517319\n","\n","Test set: Average Loss: 1.4844, Accuracy 9772/10000 (98%\n",")\n"]}],"source":["for epoch in range(1,11):\n","    train(epoch)\n","    test()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":2}
